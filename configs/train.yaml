project_path: .
model_name: dialogue4
read_format: csv
ddconfig_path: configs/ddconfigs/whale-dialogues.json

selected_columns: ["Coda1", "Ornamentation1", "Duration1", "Coda2", "Ornamentation2", "Duration2"] # should include all target column, can include additional columns
target_columns: ["Coda1", "Ornamentation1", "Duration1", "Coda2", "Ornamentation2", "Duration2"] # should include all target column, can include additional columns
target_column_types: # 'criterion' in training_spec must also be adapted
  Coda1: categorical
  Ornamentation1: categorical
  Duration1: real
  Coda2: categorical
  Ornamentation2: categorical
  Duration2: real

seq_length: 25
inference_batch_size: 1

export_onnx: true

model_spec:
  d_model: 72
  d_model_by_column: # the size of the embedding of individual variables, must sum to d_model
    Coda1: 16
    Ornamentation1: 16
    Duration1: 4
    Coda2: 16
    Ornamentation2: 16
    Duration2: 4
  nhead: 8
  d_hid: 128
  nlayers: 3
training_spec:
  device: mps
  epochs: 5000
  iter_save: 50
  batch_size: 1000
  log_interval: 3
  lr: 0.0001
  accumulation_steps: 1
  dropout: 0.2
  criterion:
    Coda1: CrossEntropyLoss
    Ornamentation1: CrossEntropyLoss
    Duration1: L1Loss
    Coda2: CrossEntropyLoss
    Ornamentation2: CrossEntropyLoss
    Duration2: L1Loss
  optimizer:
    name: AdamP
  scheduler:
    name: CosineAnnealingLR
    T_max: 111
    eta_min: 0.00001
  continue_training: false